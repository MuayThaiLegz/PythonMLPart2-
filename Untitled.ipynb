{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd657cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b20557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# change the `basepath` to the directory of the\n",
    "# unzipped movie dataset\n",
    "\n",
    "basepath = 'movie_data.csv'\n",
    "\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "#df = pd.DataFrame()\n",
    "df = pd.read_csv(basepath, encoding='utf-8' )\n",
    "\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c64f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jacklist = [\n",
    "    \n",
    "    [\"While higher interest rates, slower growth, and softer labor market conditions will bring down inflation, they will also bring some pain to households and businesses,\"],\n",
    "[\"These are the unfortunate costs of reducing inflation. But a failure to restore price stability would mean far greater pain\"],\n",
    "[\"We are moving our policy stance purposefully to a level that will be sufficiently restrictive to return inflation to 2\"],\n",
    "[\"restoring price stability will likely require maintaining a restrictive policy stance for some time. The historical recor] cautions strongly against prematurely loosening policy.\"],\n",
    "[\"will depend on the totality of the incoming data and the evolving outlook. At some point, as the stance of monetary policy tightens further, it likely will become appropriate to slow the pace of in\"],\n",
    "\n",
    "[\n",
    "    'At past Jackson Hole conferences, I have discussed broad topics such as the ever-changing structure of the economy and the challenges of conducting monetary policy under high uncertainty. Today, my remarks will be shorter, my focus narrower, and my message more direct.\\\\ Of course, inflation has just about everyone attention right now, which highlights a particular risk today: The longer the current bout of high inflation continues, the greater the chance that expectations of higher inflation will become entrenched.'],\n",
    "\n",
    "[\n",
    "    \"The Federal Open Market Committees (FOMC) overarching focus right now is to bring inflation back down to our 2 percent goal. Price stability is the responsibility of the Federal Reserve and serves as the bedrock of our economy. Without price stability, the economy does not work for anyone. In particular, without price stability, we will not achieve a sustained period of strong labor market conditions that benefit all. The burdens of high inflation fall heaviest on those who are least able to bear them.\\\\ That brings me to the third lesson, which is that we must keep at it until the job is done. History shows that the employment costs of bringing down inflation are likely to increase with delay, as high inflation becomes more entrenched in wage and price setting. The successful Volcker disinflation in the early 1980s followed multiple failed attempts to lower inflation over the previous 15 years. A lengthy period of very restrictive monetary policy was ultimately needed to stem the high inflation and start the process of getting inflation down to the low and stable levels that were the norm until the spring of last year. Our aim is to avoid that outcome by acting with resolve now.\"],\n",
    "    \n",
    "\n",
    "[\n",
    "    \"Restoring price stability will take some time and requires using our tools forcefully to bring demad and supply into better balance. Reducing inflation is likely to require a sustained period of below-trend growth. Moreover, there will very likely be some softening of labor market conditions. While higher interest rates, slower growth, and softer labor market conditions will bring down inflation, they will also bring some pain to households and businesses. These are the unfortunate costs of reducing inflation. But a failure to restore price stability would mean far greater pain.\\\\These lessons are guiding us as we use our tools to bring inflation down. We are taking forceful and rapid steps to moderate demand so that it comes into better alignment with supply, and to keep inflation expectations anchored. We will keep at it until we are confident the job is done.\"],\n",
    "\n",
    "[\n",
    "    \"The U.S. economy is clearly slowing from the historically high growth rates of 2021, which reflected the reopening of the economy following the pandemic recession. While the latest economic data have been mixed, in my view our economy continues to show strong underlying momentum. The labor market is particularly strong, but it is clearly out of balance, with demand for workers substantially exceeding the supply of available workers. Inflation is running well above 2 percent, and high inflation has continued to spread through the economy. While the lower inflation readings for July are welcome, a single month's improvement falls far short of what the Committee will need to see before we are confident that inflation is moving down.\"],\n",
    "\n",
    "[\n",
    "    \"We are moving our policy stance purposefully to a level that will be sufficiently restrictive to return inflation to 2 percent. At our most recent meeting in July, the FOMC raised the target range for the federal funds rate to 2.25 to 2.5 percent, which is in the Summary of Economic Projection's (SEP) range of estimates of where the federal funds rate is projected to settle in the longer run. In current circumstances, with inflation running far above 2 percent and the labor market extremely tight, estimates of longer-run neutral are not a place to stop or pause.\"],\n",
    "\n",
    "[\n",
    "    \"July's increase in the target range was the second 75 basis point increase in as many meetings, and I said then that another unusually large increase could be appropriate at our next meeting. We are now about halfway through the intermeeting period. Our decision at the September meeting will depend on the totality of the incoming data and the evolving outlook. At some point, as the stance of monetary policy tightens further, it likely will become appropriate to slow the pace of increases.\"],\n",
    "\n",
    "[\n",
    "    \"Restoring price stability will likely require maintaining a restrictive policy stance for some time. The historical record cautions strongly against prematurely loosening policy. Committee participants' most recent individual projections from the June SEP showed the median federal funds rate running slightly below 4 percent through the end of 2023. Participants will update their projections at the September meeting.\"],\n",
    "\n",
    "[ \n",
    "    \"Our monetary policy deliberations and decisions build on what we have learned about inflation dynamics both from the high and volatile inflation of the 1970s and 1980s, and from the low and stable inflation of the past quarter-century. In particular, we are drawing on three important lessons.\"],\n",
    "[\n",
    "    \"The first lesson is that central banks can and should take responsibility for delivering low and stable inflation. It may seem strange now that central bankers and others once needed convincing on these two fronts, but as former Chairman Ben Bernanke has shown, both propositions were widely questioned during the Great Inflation period.1 Today, we regard these questions as settled. Our responsibility to deliver price stability is unconditional. It is true that the current high inflation is a global phenomenon, and that many economies around the world face inflation as high or higher than seen here in the United States. It is also true, in my view, that the current high inflation in the United States is the product of strong demand and constrained supply, and that the Fed's tools work principally on aggregate demand. None of this diminishes the Federal Reserve's responsibility to carry out our assigned task of achieving price stability. There is clearly a job to do in moderating demand to better align with supply. We are committed to doing that job.\"],\n",
    "    \n",
    "[\n",
    "    \"The second lesson is that the public's expectations about future inflation can play an important role in setting the path of inflation over time. Today, by many measures, longer-term inflation expectations appear to remain well anchored. That is broadly true of surveys of households, businesses, and forecasters, and of market-based measures as well. But that is not grounds for complacency, with inflation having run well above our goal for some time.\"],\n",
    "    \n",
    "\n",
    "[\n",
    "    \"If the public expects that inflation will remain low and stable over time, then, absent major shocks, it likely will. Unfortunately, the same is true of expectations of high and volatile inflation. During the 1970s, as inflation climbed, the anticipation of high inflation became entrenched in the economic decisionmaking of households and businesses. The more inflation rose, the more people came to expect it to remain high, and they built that belief into wage and pricing decisions. As former Chairman Paul Volcker put it at the height of the Great Inflation in 1979, Inflation feeds in part on itself, so part of the job of returning to a more stable and more productive economy must be to break the grip of inflationary expectations.\"],\n",
    "\n",
    "[\n",
    "    \"One useful insight into how actual inflation may affect expectations about its future path is based in the concept of rational inattention. When inflation is persistently high, households and businesses must pay close attention and incorporate inflation into their economic decisions. When inflation is low and stable, they are freer to focus their attention elsewhere. Former Chairman Alan Greenspan put it this way: For all practical purposes, price stability means that expected changes in the average price level are small enough and gradual enough that they do not materially enter business and household financial decisions\"]\n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "newTest = []\n",
    "\n",
    "\n",
    "for i in jacklist:\n",
    "    newTest.append(i)\n",
    "    \n",
    "dffed = pd.DataFrame(newTest, columns=['review'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8aa9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7982bf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is seven title brazil not available'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(df.loc[0, 'review'][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a214fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test :) :( :)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\"</a>This :) is :( a test :-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0941979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5130de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in 1974 the teenager martha moxley maggie grac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok so i really like kris kristofferson and his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spoiler do not read this if you think about w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i recently bought the dvd forgetting just how ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>ok lets start with the best the building altho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>the british heritage film industry is out of c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i don t even know where to begin on this one i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>richard tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>i waited long to watch this movie also because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      in 1974 the teenager martha moxley maggie grac...          1\n",
       "1      ok so i really like kris kristofferson and his...          0\n",
       "2       spoiler do not read this if you think about w...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      i recently bought the dvd forgetting just how ...          0\n",
       "...                                                  ...        ...\n",
       "49995  ok lets start with the best the building altho...          0\n",
       "49996  the british heritage film industry is out of c...          0\n",
       "49997  i don t even know where to begin on this one i...          0\n",
       "49998  richard tyler is a little boy who is scared of...          0\n",
       "49999  i waited long to watch this movie also because...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f44562d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08003f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00b1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JBarr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f96c48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:]\n",
    "if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2407a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f805ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d64f5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e34c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34683b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c2844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# The `stop` is defined as earlier in this chapter\n",
    "# Added it here for convenience, so that this section\n",
    "# can be run as standalone without executing prior code\n",
    "# in the directory\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv)  # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bfa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329be837",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(stream_docs(path='movie_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "clf = SGDClassifier(loss='log', random_state=1)\n",
    "\n",
    "\n",
    "doc_stream = stream_docs(path='movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eee125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a147d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "pbar = pyprind.ProgBar(45)\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc28d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1cb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c64e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ee3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e4abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bb117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998b84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b54cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd81a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#dff = pd.read_csv('market.csv', encoding='utf-8', header=None)\n",
    "dff.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ad5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english',\n",
    "                        max_features=5000)\n",
    "X = count.fit_transform(marketsent['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de824e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8032903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10,\n",
    "                                random_state=123,\n",
    "                                learning_method='batch')\n",
    "X_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b47db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 5\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic %d:\" % (topic_idx + 1))\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()\\\n",
    "                        [:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab0b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "horror = X_topics[:, 5].argsort()[::-1]\n",
    "\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
    "    print('\\nHorror movie #%d:' % (iter_idx + 1))\n",
    "    print(df['review'][movie_idx][:300], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc61ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ac5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6e29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
